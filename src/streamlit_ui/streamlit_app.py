# import asyncio
# import os
# import sys

# import streamlit as st
# from langchain_core.messages import AIMessage

# # Add the parent directory to sys.path to import our agent
# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# # Import the agent
# from agent.supervisor_agent import ReActGraph

# st.set_page_config(page_title="KMA Agent Demo", page_icon="ü§ñ", layout="wide", )

# # Initialize session state
# if 'messages' not in st.session_state:
#     st.session_state.messages = []

# # Add debug toggle to session state
# if 'debug_mode' not in st.session_state:
#     st.session_state.debug_mode = False

# # App title and description
# st.title("KMA Agent Demo")

# st.markdown("""
# This is a demo of the KMA Agent, a langgraph-based agent that can help students with their questions about KMA regulations, their information, and their scores.
# """)

# # Chat interface
# st.divider()
# st.subheader("Chat with the KMA Agent")

# # Display chat messages
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.write(message["content"])

# # Initialize chat rag in session state if it doesn't exist
# if "chat_agent" not in st.session_state:
#     with st.spinner("ƒêang kh·ªüi t·∫°o tr·ª£ l√Ω ·∫£o..."):
#         # Initialize chat rag
#         st.session_state.chat_agent = ReActGraph()
#         st.session_state.chat_agent.create_graph()
#         st.session_state.chat_agent.print_mermaid()
#         st.success("Tr·ª£ l√Ω ·∫£o ƒë√£ s·∫µn s√†ng!")

# # Get user input
# user_query = st.chat_input("Type your question here...")

# # Process user input
# if user_query:
#     # Add user message to chat history
#     st.session_state.messages.append({"role": "user", "content": user_query})

#     # Display user message
#     with st.chat_message("user"):
#         st.write(user_query)

#     # Show thinking spinner
#     with st.chat_message("assistant"):
#         with st.spinner("Thinking..."):
#             # Call the agent
#             try:
#                 # response = asyncio.run(st.session_state.chat_agent.chat(user_query))
#                 response = asyncio.run(st.session_state.chat_agent.chat(user_query))
#                 last_res = response[-1]

#                 if isinstance(last_res, AIMessage):
#                     messages = last_res.content

#                 # Check if we got a fallback response
#                 if messages == "I couldn't generate a response. Please try a different query.":
#                     st.error(
#                         "The agent couldn't generate a proper response. Please try a different query or check the agent's implementation.")

#                 # Add assistant message to chat history
#                 st.session_state.messages.append({"role": "assistant", "content": messages})
#                 st.write(messages)
#             except Exception as e:
#                 error_msg = f"Error: {str(e)}"
#                 st.error(error_msg)
#                 st.session_state.messages.append({"role": "assistant", "content": error_msg})

# # Sidebar with additional information
# with st.sidebar:
#     st.header("About this Demo")
#     st.markdown("""
#     This demo showcases a langgraph agent built for KMA students.

#     """)

#     # Add a clear chat button
#     if st.button("Clear Chat"):
#         st.session_state.messages = []
#         st.rerun()

#     # Add a debug mode toggle
#     st.divider()
#     st.subheader("Debug Options")
#     debug_mode = st.checkbox("Enable Debug Mode", value=st.session_state.debug_mode)
#     if debug_mode != st.session_state.debug_mode:
#         st.session_state.debug_mode = debug_mode
#         st.rerun()

import asyncio
import os
import sys

import streamlit as st
from langchain_core.messages import AIMessage, HumanMessage

# Add the parent directory to sys.path to import our agent
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import the agent
from agent.supervisor_agent import ReActGraph

st.set_page_config(page_title="KMA Agent Demo", page_icon="ü§ñ", layout="wide")

# Initialize session state
if 'messages' not in st.session_state:
    st.session_state.messages = []  # This will be a list of dicts for display

if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []  # This will be list of BaseMessages for agent

if 'debug_mode' not in st.session_state:
    st.session_state.debug_mode = False

# App title and description
st.title("KMA Agent Demo")

st.markdown("""
This is a demo of the KMA Agent, a langgraph-based agent that can help students with their questions about KMA regulations, their information, and their scores.
""")

# Chat interface
st.divider()
st.subheader("Chat with the KMA Agent")

# Display chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# Initialize chat agent if not exists
if "chat_agent" not in st.session_state:
    with st.spinner("ƒêang kh·ªüi t·∫°o tr·ª£ l√Ω ·∫£o..."):
        st.session_state.chat_agent = ReActGraph()
        st.session_state.chat_agent.create_graph()
        st.session_state.chat_agent.print_mermaid()
        st.success("Tr·ª£ l√Ω ·∫£o ƒë√£ s·∫µn s√†ng!")

# Get user input
user_query = st.chat_input("Type your question here...")

# Process user input
if user_query:
    # Display user message
    st.session_state.messages.append({"role": "user", "content": user_query})
    st.session_state.conversation_history.append(HumanMessage(content=user_query))
    
    with st.chat_message("user"):
        st.write(user_query)

    # Show assistant "thinking"
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            try:
                # Call chat_with_memory
                response = asyncio.run(
                    st.session_state.chat_agent.chat_with_memory(
                        st.session_state.conversation_history,
                        user_query
                    )
                )

                # L∆∞u full history
                st.session_state.conversation_history = response

                # L·∫•y message cu·ªëi c√πng
                last_message = response[-1] if response else None

                if isinstance(last_message, AIMessage):
                    bot_reply = last_message.content
                else:
                    bot_reply = "I couldn't generate a response. Please try a different query."

                st.session_state.messages.append({"role": "assistant", "content": bot_reply})
                st.write(bot_reply)

            except Exception as e:
                error_msg = f"Error: {str(e)}"
                st.session_state.messages.append({"role": "assistant", "content": error_msg})
                st.error(error_msg)

# Sidebar
with st.sidebar:
    st.header("About this Demo")
    st.markdown("""
    This demo showcases a langgraph agent built for KMA students.
    """)

    if st.button("Clear Chat"):
        st.session_state.messages = []
        st.session_state.conversation_history = []
        st.rerun()

    st.divider()
    st.subheader("Debug Options")
    debug_mode = st.checkbox("Enable Debug Mode", value=st.session_state.debug_mode)
    if debug_mode != st.session_state.debug_mode:
        st.session_state.debug_mode = debug_mode
        st.rerun()
